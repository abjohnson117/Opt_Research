{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import svdvals\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 40\n",
    "n = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first set up the problem\n",
    "\\begin{align*}\n",
    "    Ax = b\n",
    "\\end{align*}\n",
    "where we $A$ is a random, standard Gaussian matrix of dimension $m \\times n$ (where the actual size of $m,n$ are defined in the cell immediately above), the true $x$ has 10 randomly selected spikes, and $b$ is given by\n",
    "\\begin{align*}\n",
    "    b = Ax + \\gamma y\n",
    "\\end{align*}\n",
    "where $y$ is a standard Gaussian noise vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.2\n",
    "A = np.random.normal(0,1,(m,n))\n",
    "x_true = np.zeros(n)\n",
    "idx_spike = np.random.randint(0,n,10)\n",
    "x_true[idx_spike] = 100\n",
    "b = np.dot(A,x_true) + gamma*np.random.normal(0,1,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we initialize a first \"guess\" for $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init = np.ones(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to find a potential answer to our inverse problem and solve for some $x$. To do this, we first calculate the $\\lambda$ hyperparameter used in the regularized linear least squares problem:\n",
    "\\begin{align*}\n",
    "     \\displaystyle \\min_{x} \\frac{1}{2}||Ax - b||^{2} + \\lambda R(Cx).\n",
    "\\end{align*}\n",
    "Since we are first implementing the lasso method, we know necessarily that $R(Cx) = ||x||_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 10/np.linalg.norm(np.dot(A.T, b),ord=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we are going to implement the Lasso method. Since Lasso necessarily uses the $||\\cdot ||_1$ norm, then we define \n",
    "\\begin{align}\n",
    "    \\mathrm{prox}_{\\lambda || \\cdot ||_1}(x) = \\mathrm{sign}(x)\\mathrm{max}(|x|-\\lambda,0)\n",
    "\\end{align}\n",
    "Note, it is necessary that $x \\in \\mathbb{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a maximum function that compares every element in a $\\verb+numpy+$ array to a desired number (of type float or int) and returns a vector of like dimension that has taken the maximum value between the desired number and every element in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_function(x, num_compare):\n",
    "    return np.array([i if i >= num_compare else num_compare for i in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function implements formula (1). Note that every operation is completed entry-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox_op(x,lambd):\n",
    "    return np.sign(x)*max_function(np.abs(x)-lambd,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_A = svdvals(A)[0]\n",
    "eta = 0.001\n",
    "k = 0\n",
    "tol = 0.00001\n",
    "max_step = 100\n",
    "assert eta <= 1/(cond_A**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a $\\verb+lasso+$ function that will perform the desired prox-gradient descent and solve the inverse problem constructed, with the intent of creating an $\\verb+x_guess+$ vector that is as close to $\\verb+x_true+$ as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso(x, max_step, k, eta, lam, tol):\n",
    "    start = time.time()\n",
    "    while (max_step > tol):\n",
    "        k += 1\n",
    "        x_old = x\n",
    "        x = prox_op(x_old - eta*(A.T)@((A@x_old)-b),lam)\n",
    "        step = abs(x - x_old)\n",
    "        max_step = step.max()\n",
    "    end = time.time()\n",
    "    return x, start, end, k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to run our $\\verb+lasso+$ function and see if, at the very least, it includes the nonzero entries inside our $\\verb+x_true+$ vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_guess, start, end, iters = lasso(x_init, max_step, k, eta, lam, tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_guess_nonzero = np.nonzero(x_guess)\n",
    "x_true_nonzero = np.nonzero(x_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isin(x_true_nonzero, x_guess_nonzero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what is directly above, we see clearly that all the nonzero entries inside our true solution $\\verb+x_true+$ are at least inside the solution given by the lasso regression, $\\verb+x_guess+$. Though, note that the number of nonzero entries in $\\verb+x_guess+$ is greater than that of $\\verb+x_true+$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of nonzero entries in x_guess: 30\n",
      "This is the number of nonzero entries in x_true: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"This is the number of nonzero entries in x_guess: \" + str(len(x_guess_nonzero[0])))\n",
    "print(\"This is the number of nonzero entries in x_true: \" + str(len(x_true_nonzero[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, there is imprecision in that we would prefer to have more entries in $\\verb+x_guess+$ to be closer to 0.\n",
    "\n",
    "We also show the number of iterations and the time it takes for the lasso method to converge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of iterations required for lasso to converge: 249805\n",
      "This is the number of seconds it takes for lasso to converge: 11.443709135055542\n"
     ]
    }
   ],
   "source": [
    "print(\"This is the number of iterations required for lasso to converge: \" + str(iters))\n",
    "print(\"This is the number of seconds it takes for lasso to converge: \" + str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare the above to the SR3 method. For reference, the general SR3 formulation is as follows:\n",
    "\\begin{align*}\n",
    "    \\displaystyle \\min_{x,w} \\frac{1}{2}||Ax-b||^{2} + \\lambda R(w) + \\frac{\\kappa}{2}||Cx - w||^{2}.\n",
    "\\end{align*}\n",
    "We first want to recover a relaxed version of lasso. To do this, we take $R(\\cdot) = ||\\cdot ||_{1}$ and $C=I$. In this instance as well, we take $\\kappa = 1$. We proceed as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.eye(n,n)\n",
    "kappa = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
